# Probabilistic Data Structures: Good Enough is Perfect âœ¨


* **`01-concepts-01-the-core-problem.md`**: How can we answer questions about massive datasets using a tiny amount of memory, if we can accept a small chance of error?
* **`01-concepts-02-the-guiding-philosophy.md`**: Trading certainty for efficiency. The idea is to design data structures that can answer questions like "Have I seen this item before?" without storing all the items.
* **`01-concepts-03-key-abstractions.md`**: Introduces the concepts of `false positives` and `hashing` as a core building block. Focuses on Bloom filters and HyperLogLog.
* **`02-guides-01-bloom-filter-basics.md`**: A guide to implementing a simple Bloom filter to check for the existence of usernames in a massive (simulated) database.
* **`03-deep-dive-01-tuning-for-error.md`**: A mental model for the trade-off between memory usage and the false positive rate. How to choose the right number of hash functions and bits.

---
